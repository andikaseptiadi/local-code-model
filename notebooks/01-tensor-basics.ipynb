{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Tensor Basics and Operations\n",
    "\n",
    "This notebook introduces the `Tensor` type, which is the foundational data structure for all neural network operations in this project.\n",
    "\n",
    "## What is a Tensor?\n",
    "\n",
    "A tensor is a multi-dimensional array - think of it as a generalization of:\n",
    "- **Scalar** (0D): A single number\n",
    "- **Vector** (1D): An array of numbers `[1, 2, 3]`\n",
    "- **Matrix** (2D): A grid of numbers\n",
    "- **3D+ Tensor**: Higher-dimensional grids\n",
    "\n",
    "In deep learning, tensors represent:\n",
    "- **Inputs**: Text, images, audio (as numbers)\n",
    "- **Weights**: Learned parameters of the model\n",
    "- **Activations**: Intermediate computations\n",
    "- **Gradients**: How to update weights\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the local-code-model package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"github.com/scttfrdmn/local-code-model\"\n",
    ")\n",
    "\n",
    "// Alias for convenience\n",
    "type Tensor = main.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensors\n",
    "\n",
    "### 1. From a Slice (Most Common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a 1D tensor (vector)\n",
    "vec := main.NewTensor([]int{3}, []float64{1.0, 2.0, 3.0})\n",
    "fmt.Printf(\"Vector shape: %v\\n\", vec.Shape())\n",
    "fmt.Printf(\"Vector data: %v\\n\\n\", vec.Data())\n",
    "\n",
    "// Create a 2D tensor (matrix)\n",
    "matrix := main.NewTensor([]int{2, 3}, []float64{\n",
    "    1.0, 2.0, 3.0,  // Row 0\n",
    "    4.0, 5.0, 6.0,  // Row 1\n",
    "})\n",
    "fmt.Printf(\"Matrix shape: %v\\n\", matrix.Shape())\n",
    "fmt.Printf(\"Matrix data: %v\\n\", matrix.Data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Special Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// All zeros\n",
    "zeros := main.Zeros(2, 3)\n",
    "fmt.Printf(\"Zeros (2x3):\\n%v\\n\\n\", zeros.Data())\n",
    "\n",
    "// All ones\n",
    "ones := main.Ones(2, 3)\n",
    "fmt.Printf(\"Ones (2x3):\\n%v\\n\\n\", ones.Data())\n",
    "\n",
    "// Random values (Xavier initialization)\n",
    "random := main.RandN(2, 3)\n",
    "fmt.Printf(\"Random (2x3):\\n%v\\n\", random.Data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Shape and Indexing\n",
    "\n",
    "Understanding tensor shape is crucial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create a 3D tensor: (batch_size=2, sequence_length=3, embedding_dim=4)\n",
    "embeddings := main.RandN(2, 3, 4)\n",
    "\n",
    "fmt.Printf(\"Shape: %v\\n\", embeddings.Shape())\n",
    "fmt.Printf(\"Dimensions: %d\\n\", len(embeddings.Shape()))\n",
    "fmt.Printf(\"Total elements: %d\\n\\n\", len(embeddings.Data()))\n",
    "\n",
    "// Accessing elements\n",
    "val := embeddings.At(0, 1, 2)  // batch 0, position 1, dimension 2\n",
    "fmt.Printf(\"Element at [0,1,2]: %.4f\\n\", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Operations\n",
    "\n",
    "### Matrix Multiplication (MatMul)\n",
    "\n",
    "The most important operation in neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Matrix A: 2x3\n",
    "A := main.NewTensor([]int{2, 3}, []float64{\n",
    "    1, 2, 3,\n",
    "    4, 5, 6,\n",
    "})\n",
    "\n",
    "// Matrix B: 3x2\n",
    "B := main.NewTensor([]int{3, 2}, []float64{\n",
    "    1, 2,\n",
    "    3, 4,\n",
    "    5, 6,\n",
    "})\n",
    "\n",
    "// C = A @ B (result: 2x2)\n",
    "C := A.MatMul(B)\n",
    "\n",
    "fmt.Printf(\"A (%v) @ B (%v) = C (%v)\\n\", A.Shape(), B.Shape(), C.Shape())\n",
    "fmt.Printf(\"C =\\n\")\n",
    "for i := 0; i < 2; i++ {\n",
    "    for j := 0; j < 2; j++ {\n",
    "        fmt.Printf(\"  %.0f\", C.At(i, j))\n",
    "    }\n",
    "    fmt.Println()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x := main.NewTensor([]int{2, 2}, []float64{1, 2, 3, 4})\n",
    "y := main.NewTensor([]int{2, 2}, []float64{10, 20, 30, 40})\n",
    "\n",
    "// Addition\n",
    "sum := x.Add(y)\n",
    "fmt.Printf(\"x + y = %v\\n\", sum.Data())\n",
    "\n",
    "// Subtraction\n",
    "diff := x.Sub(y)\n",
    "fmt.Printf(\"x - y = %v\\n\", diff.Data())\n",
    "\n",
    "// Element-wise multiplication (Hadamard product)\n",
    "prod := x.Mul(y)\n",
    "fmt.Printf(\"x * y = %v\\n\", prod.Data())\n",
    "\n",
    "// Scalar multiplication\n",
    "scaled := x.Scale(5.0)\n",
    "fmt.Printf(\"x * 5 = %v\\n\", scaled.Data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Operations work across different shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Matrix + Vector (broadcasts vector across rows)\n",
    "matrix := main.NewTensor([]int{2, 3}, []float64{1, 2, 3, 4, 5, 6})\n",
    "vec := main.NewTensor([]int{3}, []float64{10, 20, 30})\n",
    "\n",
    "result := matrix.Add(vec)\n",
    "fmt.Printf(\"Matrix shape: %v\\n\", matrix.Shape())\n",
    "fmt.Printf(\"Vector shape: %v\\n\", vec.Shape())\n",
    "fmt.Printf(\"Result shape: %v\\n\", result.Shape())\n",
    "fmt.Printf(\"Result: %v\\n\", result.Data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Non-linear transformations that make neural networks powerful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x := main.NewTensor([]int{5}, []float64{-2.0, -1.0, 0.0, 1.0, 2.0})\n",
    "\n",
    "// ReLU: max(0, x)\n",
    "relu := x.ReLU()\n",
    "fmt.Printf(\"ReLU(%v) = %v\\n\", x.Data(), relu.Data())\n",
    "\n",
    "// GELU: Gaussian Error Linear Unit (smoother than ReLU)\n",
    "gelu := x.GELU()\n",
    "fmt.Printf(\"GELU(%v) = %v\\n\", x.Data(), gelu.Data())\n",
    "\n",
    "// Softmax: converts to probability distribution\n",
    "logits := main.NewTensor([]int{3}, []float64{1.0, 2.0, 3.0})\n",
    "probs := logits.Softmax(0)\n",
    "fmt.Printf(\"Softmax(%v) = %v\\n\", logits.Data(), probs.Data())\n",
    "fmt.Printf(\"Sum of probabilities: %.4f\\n\", probs.Sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and Transposing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create 1D tensor\n",
    "flat := main.NewTensor([]int{12}, []float64{\n",
    "    1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
    "})\n",
    "\n",
    "// Reshape to 2D\n",
    "mat := flat.Reshape(3, 4)\n",
    "fmt.Printf(\"Reshaped to %v:\\n\", mat.Shape())\n",
    "for i := 0; i < 3; i++ {\n",
    "    for j := 0; j < 4; j++ {\n",
    "        fmt.Printf(\"%5.0f\", mat.At(i, j))\n",
    "    }\n",
    "    fmt.Println()\n",
    "}\n",
    "\n",
    "// Transpose (swap dimensions)\n",
    "transposed := mat.Transpose(0, 1)\n",
    "fmt.Printf(\"\\nTransposed to %v:\\n\", transposed.Shape())\n",
    "for i := 0; i < 4; i++ {\n",
    "    for j := 0; j < 3; j++ {\n",
    "        fmt.Printf(\"%5.0f\", transposed.At(i, j))\n",
    "    }\n",
    "    fmt.Println()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data := main.NewTensor([]int{2, 3}, []float64{\n",
    "    1, 2, 3,\n",
    "    4, 5, 6,\n",
    "})\n",
    "\n",
    "// Sum all elements\n",
    "total := data.Sum()\n",
    "fmt.Printf(\"Sum: %.0f\\n\", total)\n",
    "\n",
    "// Mean\n",
    "avg := data.Mean()\n",
    "fmt.Printf(\"Mean: %.2f\\n\", avg)\n",
    "\n",
    "// Variance and standard deviation\n",
    "variance := data.Variance()\n",
    "stddev := data.StdDev()\n",
    "fmt.Printf(\"Variance: %.4f\\n\", variance)\n",
    "fmt.Printf(\"Std Dev: %.4f\\n\", stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Tensors are multi-dimensional arrays** - the foundation of deep learning\n",
    "2. **Shape matters** - operations require compatible shapes\n",
    "3. **MatMul is king** - most neural network computation is matrix multiplication\n",
    "4. **Activations add non-linearity** - without them, networks are just linear functions\n",
    "5. **Reshaping is common** - data flows through different shapes in a network\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand tensors, you're ready to:\n",
    "- **Notebook 2**: Build the attention mechanism from scratch\n",
    "- **Notebook 3**: Train a complete transformer model\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Try creating a simple linear layer: `y = x @ W + b`\n",
    "\n",
    "Where:\n",
    "- `x` is input (batch_size=2, input_dim=3)\n",
    "- `W` is weights (input_dim=3, output_dim=4)\n",
    "- `b` is bias (output_dim=4)\n",
    "- `y` is output (batch_size=2, output_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Implement linear layer\n",
    "// x := main.RandN(2, 3)\n",
    "// W := main.RandN(3, 4)\n",
    "// b := main.RandN(4)\n",
    "// y := ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
